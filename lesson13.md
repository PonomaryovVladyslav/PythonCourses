# Лекция 13. Тестирование

### Оглавление курса

<details>
  <summary>Блок 1 — Python Basic (1–6)</summary>

  - [Лекция 1. Введение. Типизация. Переменные. Строки и числа. Булева алгебра. Ветвление](lesson01.md)
  - [Лекция 2. Обработка исключений. Списки, строки детальнее, срезы, циклы](lesson02.md)
  - [Лекция 3. None. Range, list comprehension, sum, max, min, len, sorted, all, any. Работа с файлами](lesson03.md)
  - [Лекция 4. Хэш-таблицы. Set, frozenset. Dict. Tuple. Немного об импортах. Namedtuple, OrderedDict](lesson04.md)
  - [Лекция 5. Функции, типизация, lambda. Map, zip, filter](lesson05.md)
  - [Лекция 6. Алгоритмы и структуры данных](lesson06.md)
</details>

<details>
  <summary>Блок 2 — Git (7–8)</summary>

  - [Лекция 7. Git. История системы контроля версий. Локальный репозиторий. Базовые команды управления репозиторием.](lesson07.md)
  - [Лекция 8. Git. Удаленный репозиторий. Remote, push, pull. GitHub, Bitbucket, GitLab, etc. Pull request.](lesson08.md)
</details>

<details open>
  <summary>Блок 3 — Python Advanced (9–14)</summary>

  - [Лекция 9. Введение в ООП. Основные парадигмы ООП. Классы и объекты. Множественное наследование.](lesson09.md)
  - [Лекция 10. Magic methods. Итераторы и генераторы.](lesson10.md)
  - [Лекция 11. Imports. Standard library. PEP8](lesson11.md)
  - [Лекция 12. Декораторы. Декораторы с параметрами. Декораторы классов (staticmethod, classmethod, property)](lesson12.md)
  - ▶ **Лекция 13. Тестирование**
  - [Лекция 14. Проектирование. Паттерны. SOLID.](lesson14.md)
</details>

<details>
  <summary>Блок 4 — SQL (15–17)</summary>

  - [Лекция 15. СУБД. PostgreSQL. SQL. DDL. Пользователи. DCL. DML. Связи.](lesson15.md)
  - [Лекция 16. СУБД. DQL. SELECT. Индексы. Group by. Joins.](lesson16.md)
  - [Лекция 17. СУБД. Нормализация. Аномалии. Транзакции. ACID. TCL. Backup](lesson17.md)
</details>

- [Лекция 18. Virtual env. Pip. Устанавливаемые модули. Pyenv.](lesson18.md)

<details>
  <summary>Блок 5 — Django (19–26)</summary>

  - [Лекция 19. Знакомство с Django](lesson19.md)
  - [Лекция 20. Templates. Static](lesson20.md)
  - [Лекция 21. Модели. Связи. Meta. Abstract, proxy.](lesson21.md)
  - [Лекция 22. Django ORM.](lesson22.md)
  - [Лекция 23. Forms, ModelForms. User, Authentication.](lesson23.md)
  - [Лекция 24. ClassBaseView](lesson24.md)
  - [Лекция 25. NoSQL. Куки, сессии, кеш](lesson25.md)
  - [Лекция 26. Логирование. Middleware. Signals. Messages. Manage commands](lesson26.md)
</details>

<details>
  <summary>Блок 6 — Django Rest Framework (27–30)</summary>

  - [Лекция 27. Что такое API. REST и RESTful. Django REST Framework.](lesson27.md)
  - [Лекция 28. @api_view, APIView, ViewSets, Pagination, Routers](lesson28.md)
  - [Лекция 29. REST аутентификация. Авторизация. Permissions. Фильтрация.](lesson29.md)
  - [Лекция 30. Тестирование. Django, REST API.](lesson30.md)
</details>

<details>
  <summary>Блок 7 — Python async (31–33)</summary>

  - [Лекция 31. Celery. Multithreading. GIL. Multiprocessing](lesson31.md)
  - [Лекция 32. Asyncio. Aiohttp. Асинхронное программирование на практике.](lesson32.md)
  - [Лекция 33. Сокеты. Django channels.](lesson33.md)
</details>

<details>
  <summary>Блок 8 — Deployment (34–35)</summary>

  - [Лекция 34. Linux. Все что нужно знать для деплоймента.](lesson34.md)
  - [Лекция 35. Deployment](lesson35.md)
</details>

- [Лекция 36. Методологии разработки. CI/CD. Монолит и микросервисы. Docker](lesson36.md)


![](https://memchik.ru//images/memes/5f9a99ffb1c7e326eb75f4ef.jpg)

## Общая информация

Тестирование — это огромная, нет **ОГРОМНАЯ** тема, настолько огромная, что порождает несколько отдельных видов
сотрудников в IT-индустрии.

### Исследование против плана

Хорошая новость в том, что вы, вероятно, уже создавали тесты, не осознавая этого. Помните, когда вы запускали приложение
и использовали его впервые? Вы проверяли функции и экспериментировали с ними? Это называется исследовательским
тестированием и является формой ручного тестирования.

Исследовательское тестирование — это форма тестирования, которая проводится без плана. В таком виде тестирования вы
просто изучаете приложение.

Чтобы получить полный набор ручных тестов, необходимо выполнить следующие шаги:

- составить список всех функций, которыми обладает ваше приложение;
- составить список различных типов входных данных, которые оно может принять;
- составить список всех ожидаемых результатов.

Теперь каждый раз, когда вы будете вносить изменения в свой код, вам нужно просмотреть каждый элемент в этом списке и
проверить его правильность.

Это не особо прикольно?

Вот где приходит на помощь **тест-план**.

Тест-план — это разделение вашего приложения на минимальные части и описание ожидаемой работы функционала каждой части,
порядка их выполнения и ожидаемых результатов.

> Если у вас есть тест-план, вы можете каждый раз проходить по всем его пунктам и быть уверенным, что проверили всё. В
> случае обновления приложения необходимо обновить и план.

### Виды тестирования

На самом деле, как я и сказал, тестирование — это очень много подвидов различной деятельности. Найти абсолютно полную
таблицу со всеми деталями невозможно, всегда можно ещё что-либо добавить.

Но давайте поверхностно посмотрим на вот эту таблицу:

![](https://static.tildacdn.com/tild3137-6364-4834-b738-353565626438/photo.png)

Вот текст с описанием каждого вида тестирования, представленного в схеме:

1. **По доступности кода:**
    - **Черного ящика (Black Box testing):** Тестирование проводится без знания внутренней структуры системы.
      Проверяются функциональные требования.
    - **Серого ящика (Grey Box testing):** Тестирование проводится с частичным знанием внутренней структуры системы.
      Проверяются и функциональные, и некоторые нефункциональные требования.
    - **Белого ящика (White Box testing):** Тестирование проводится с полным знанием внутренней структуры системы.
      Проверяются внутренние механизмы и логика работы системы.

2. **По объекту (предмету) тестирования:**
    - **Интерфейса пользователя (UI testing):** Проверка удобства и правильности работы пользовательского интерфейса.
    - **Локализации (Localization testing):** Проверка правильности адаптации ПО для различных языков и регионов.
    - **Скорости и надежности (Speed/Stress/Performance testing):** Проверка производительности и устойчивости системы
      под нагрузкой.
    - **Безопасности (Security testing):** Проверка системы на уязвимости и защиты от различных видов атак.
    - **Удобства использования пользователем (Usability/UX testing):** Проверка удобства и интуитивности использования
      системы для конечных пользователей.
    - **Совместимости (Compatibility testing):** Проверка корректности работы системы в различных средах (операционные
      системы, браузеры и т.д.).
    - **Функциональное (Functional testing):** Проверка корректности выполнения всех заявленных функций системы.

3. **По позитивности сценариев:**
    - **Позитивное (Positive testing):** Проверка системы на корректное поведение при введении ожидаемых данных.
    - **Негативное (Negative testing):** Проверка системы на устойчивость к введению неожиданных или некорректных
      данных.

4. **По времени проведения:**
    - **Альфа (Alpha testing):** Внутреннее тестирование, проводимое разработчиками или тестировщиками внутри компании.
    - **Бета (Beta testing):** Внешнее тестирование, проводимое потенциальными или реальными пользователями.
    - **Дымовое (Smoke test):** Быстрая проверка основных функций системы для выявления грубых ошибок.
    - **Санитарное или Соответствия (Sanity/Confidence test):** Проверка работоспособности после внесения небольших
      изменений.
    - **Новых функциональностей (New feature test):** Тестирование вновь добавленных функций.
    - **Регрессионное (Regression test):** Проверка существующего функционала после внесения изменений в систему.
    - **Приемочное (Acceptance or Certification test):** Финальная проверка системы перед передачей заказчику или
      выпуском в продакшн.

5. **По уровням тестирования:**
    - **Компонентное (Component testing):** Проверка отдельных компонентов или модулей системы.
    - **Интеграционное (Integration testing):** Проверка взаимодействия между компонентами системы.
    - **Системное (System or End to end testing):** Проверка всей системы целиком на соответствие требованиям.

6. **По автоматизированности:**
    - **Ручное (Manual testing):** Тестирование, проводимое вручную тестировщиком.
    - **Автоматизированное (Automation testing):** Тестирование с использованием автоматизированных скриптов и
      инструментов.
    - **Полуавтоматизированное (Semi automated testing):** Сочетание ручного и автоматизированного тестирования.

7. **По степени подготовки:**
    - **По документации (Formal/Documented testing):** Тестирование, проводимое по заранее подготовленным сценариям и
      планам.
    - **Интуитивное (Ad hoc testing):** Спонтанное тестирование без заранее подготовленных планов и сценариев.

8. **По субъекту:**
    - **Альфа-тестировщик штатный (Alfa-tester):** Внутренний сотрудник компании, занимающийся тестированием.
    - **Бета-тестировщик внешний (Beta-tester):** Внешний пользователь, привлекаемый для тестирования системы.

Так вот. Например, performance- и security-тестирование (penetration) выполняют отдельные специалисты (ну если они есть).

И если вы думаете, что тестирование — это для тестировщиков, а мы тут вроде на программистов учимся, то у меня для вас
плохие новости. Очень весомую часть своего рабочего времени программист тратит на тестирование!

## Уровни тестирования

Подумайте, как вы можете проверить свет фар в автомобиле. Вам нужно запустить фары, после чего выйти из машины и
посмотреть, горят ли фары. Проверка на то, что фары вообще горят, называется ассерцией (assert), но на самом деле
вариантов что можно проверить невероятно много.

![](https://habrastorage.org/storage2/ec3/825/c7f/ec3825c7f0710f9fed6814c89b794ded.jpg)

Существует 4 основных уровня тестирования функционала.

### Модульные тесты

> **Модульные тесты (Unit Tests)** — это тесты, проверяющие функционал конкретного модуля минимального размера.
> Если вы написали функцию или метод, то юнит-тестом будет попытка вызвать этот метод с разными входными
> данными и посмотреть на то, что вернёт результат. Пример из модуля: функция для создания задачи. Передать туда все
> возможные варианты входных данных и убедиться, что, что бы мы туда ни передали, функция всегда ведёт себя как
> ожидается.

В примере с фарами предположим, что фара не горит. А почему? Вот тут мы подходим к понятию unit-тестинга.
Мы должны проверить каждый минимальный компонент системы. Что кнопка действительно нажимается, что при нажатии ток идет
по проводам, причем с правильным напряжением и силой тока. Что провод передает ток лампочке. Что лампочка исправна и
когда ток до нее доходит, то она загорается.

В вашем написанном коде всё точно так же. Почти любое действие — это совокупность какого-то количества функций/методов
и т. д.

Unit-тестирование — это тестирование каждого отдельного минимально возможного компонента.

### Интеграционные тесты

> **Интеграционные тесты (Integration Tests)** — это вид тестирования, когда проверяется целостность работы системы, без
> сторонних средств. Пример из вашего модуля. Вы пишете тест, который запускает полный набор действий для создания
> заметки. И в качестве проверки должно быть создание файла, в котором появилась новая задача.

Интеграционный тест — это тест цельной системы на какое-либо допустимое действие. Проверка, что написанный код выполняет
что ожидалось.

Основная проблема с интеграционным тестированием — это когда интеграционный тест не дает правильного результата. Иногда
очень трудно диагностировать проблему, не имея возможности определить, какая часть системы вышла из строя. Если фары не
включились, то, возможно, сломаны лампы или разряжен аккумулятор. А как насчет генератора? Или может быть сломан
компьютер машины?

Одни тесты не заменяют других. Без юнитов мы не можем узнать, работает ли каждый элемент по отдельности. Без
интеграционных мы не знаем, работает ли система целиком.

> **Приёмочные тесты (Acceptance Tests)** — вид тестов с полной имитацией действий пользователя. Прописываются
> относительно редко.
> Для вашего модуля это был бы код, который полностью открывает консоль, запускает файл и вводит туда какие-либо данные
> после чего проверяет результат на выходе.

Когда мы доберёмся до веба, я покажу специальные средства (например, Selenium), которые за нас будут открывать браузер,
искать необходимые элементы на странице, имитировать ввод данных, нажатие кнопок, переход по ссылкам и т. д.

На данном этапе нас эти тесты не интересуют (честно говоря, и потом не сильно будут интересовать).

> **Ручные тесты (Manual Tests)** — вид тестов, когда мы полностью повторяем потенциальные действия пользователя.

Если вы хоть раз запускали свой код, значит, вы проводили ручное исследовательское тестирование, только об этом не знали.

> Помните: нельзя закончить писать тесты, можно только перестать!

### Как это вообще работает?

Теоретически можно написать рабочий проект вообще без единого теста (ваш модуль тому пример). Но чем больше и сложнее
система, тем дороже стоимость ошибки или объем затраченного времени на поиск причины этой ошибки.

В реальности даже не сильно большой проект не сможет существовать без тестирования.

## Кто все это пишет?

### Люди в тестировании

Из тех, с кем вы реально можете столкнуться:

- Другие разработчики (Они же `dev` — developer, `SE` — software engineer)
- Автоматизированные тестировщики (Они же `AQA` — automation quality assurance, `SDET` — software development engineer
  in test)
- Мануальные тестировщики (Тут без терминов, максимум мануальщики)

В целом любых тестировщиков называют `QA` (quality assurance) или иногда `QC` (quality control).

### Зачем нам все эти люди

#### Кто пишет юнит тесты?

Юнит-тесты — это тесты конкретно написанной функции или метода. А значит, знание о том, как это работает, есть
только у разработчика, а значит, их пишет разработчик.

- `Идеальный мир` — разработчик покрывает всё тестами.

- `Реальность` — разработчик покрывает основной функционал и тонкие места тестами.

- `Худший случай` — юнит-тестов нет, что приводит к усложнению написания и модификации проекта в несколько раз.

#### Кто пишет интеграционные тесты?

- `Идеальный мир` — автоматизированные тестировщики, причём вполне возможно, что на другом языке программирования, связь
  вообще не обязательна.

- `Реальность` — автоматизаторы, если они есть, разработчики, если автоматизаторов нет. Но даже если автоматизаторы есть,
  бывают интеграционные тесты, которые нужны вам самим как разработчикам, тогда они ни при чём, и этим занимаемся тоже мы.

- `Худший случай` — нет интеграционных тестов. Что приводит к тому, что при внедрении новых фич можно не узнать о том,
  что сломалась старая. Это приводит к тому, что функционал будет отваливаться быстрее, чем разрабатываться.

#### Кто пишет приёмочные тесты?

- `Идеальный мир` — всё те же автоматизаторы.

- `Реальность` — у кого есть время и желание, чаще всего этот вид тестирования либо игнорируется, либо выполняется,
  когда уже всё остальное написано. Также бывает, когда через такой вид тестирования мануальщиков обучают и привлекают к
  автоматизации.

- `Худший случай` — приёмочных тестов нет, и в случае отсутствия мануальной проверки можно не узнать, что функционал в
  браузере больше не работает.

#### Кто выполняет ручные тесты?

- `Идеальный мир` — мануальные тестировщики.

- `Реальность` — если есть мануальные тестировщики, то они, если нет, то автоматизаторы, если и их нет, то разработчики
  в процессе разработки.

- `Худший случай` — не проводятся, уверенность, что функционал работает, равна нулю.

> Нельзя закончить писать тесты, можно только перестать.

## assert

Ключевое слово `assert` является основным инструментом для тестирования. Как это работает? По сути `assert` — это только
надстройка над конструкцией `raise`:

После `assert` нужно указать какое-то выражение или через запятую передать выражение и текст ошибки.

Если выражение после преобразования в булево значение является истинным (`True`), то код продолжает работать дальше, а если нет (`False`), то останавливает выполнение и выбрасывает ошибку: если она описана — с текстом, если нет — без.

Давайте глянем на примеры:

```python
assert 1  # Все хорошо, этот код, отработает и перейдет на следующую строчку
assert 0  # Мы увидим ошибку
assert 4 == 5, "4 is not equal to 5"  # Мы увидим ошибку которую сами и написали
```

По сути весь код сверху — это просто обёртка над вот такой конструкцией:

```python
condition = 4 == 5
message = "4 is not equal to 5"
if not condition:
    raise AssertionError(message)
```

> Но так в реальности никто не пишет!
> Важно: при запуске Python с флагом -O выражения assert удаляются. В продакшен‑коде не используйте assert для валидации входных данных; в unittest предпочитайте методы assert*.


## TestCase

Помните, мы говорили о том, что бывает исследовательское тестирование и тестирование с планом? Так вот, когда мы тестируем что-либо с
планом, наш план чаще всего состоит из тест-кейсов для конкретного функционала.

Например, в вашем модуле, есть создание, изменение и удаление задачи. Это три разных теста, которые можно объединить в
один тест-кейс. Обработка задач.

> По-хорошему, весь функционал должен быть разбит на небольшие логически связанные куски и задокументирован как план
> тестирования, состоящий из множества тест-кейсов.

## Тестовые фреймворки и что это вообще такое

### Фреймворк

`Фреймворк (framework)` — это структурированная платформа для разработки программного обеспечения, предоставляющая набор
готовых компонентов, инструментов и библиотек, которые упрощают и ускоряют процесс разработки. Фреймворки обеспечивают
стандартный способ создания и организации кода, что способствует повышению эффективности и качества разработки.

Если простыми словами, то это конструктор (как лего) из готовых элементов, которые остаётся только собрать, — не нужно
каждую детальку вытачивать по отдельности.

### Какие бывают тестовые фреймворки для Python

Технически их довольно много, вот основные:

1. **unittest**:
    - **Описание**: Встроенный в стандартную библиотеку Python, unittest предоставляет базовый функционал для создания и
      выполнения тестов.
    - **Особенности**: Поддержка организации тестов в тестовые наборы (test suites), классы и методы для создания
      тестов, средства для проверок (assertions).

2. **pytest**:
    - **Описание**: Один из самых популярных фреймворков для тестирования в Python, благодаря своей простоте и
      расширяемости.
    - **Особенности**: Простота использования, поддержка фикстур (fixtures), мощная система плагинов, хорошая интеграция
      с другими инструментами.

3. **nose2**:
    - **Описание**: Продолжение проекта nose, который больше не поддерживается. nose2 сохраняет философию nose,
      обеспечивая автоматическое обнаружение тестов и совместимость с unittest.
    - **Особенности**: Простота настройки, поддержка плагинов, совместимость с тестами, написанными для unittest.

4. **doctest**:
    - **Описание**: Фреймворк, встроенный в стандартную библиотеку Python, который позволяет писать тесты прямо в
      документационных строках (docstrings).
    - **Особенности**: Простой способ проверки корректности примеров кода в документации, минимальная настройка.

5. **Hypothesis**:
    - **Описание**: Библиотека для тестирования на основе свойств (property-based testing), которая генерирует случайные
      входные данные для ваших тестов.
    - **Особенности**: Генерация широкого спектра тестовых случаев, автоматическое обнаружение граничных условий,
      интеграция с unittest и pytest.

6. **tox**:
    - **Описание**: Инструмент для автоматизации тестирования в разных средах.
    - **Особенности**: Поддержка нескольких сред выполнения, интеграция с различными системами сборки и CI/CD,
      управление зависимостями.

7. **robot framework**:
    - **Описание**: Фреймворк для тестирования на уровне системы с использованием тестовых сценариев, написанных на
      естественном языке.
    - **Особенности**: Поддержка ключевых слов (keyword-driven testing), возможность расширения с помощью библиотек
      Python, хорошие возможности для создания отчетов.

Но так как пока что мы не умеем работать с устанавливаемыми модулями (научимся через 5 занятий), наш выбор падает
на `unittest`. Он входит в стандартную библиотеку Python и покрывает весь необходимый нам функционал.

> На реальных проектах я гораздо чаще видел `pytest`, но они все работают на очень похожих принципах, поэтому нет
> никакой проблемы перейти с одного на другой.

## К реальности

Тесты практически всегда пишут в виде тест-кейсов, причём разделяя модульные и интеграционные (иногда ещё приёмочные — acceptance).

Для запуска тестов используются так называемые `test runner` — это специальное приложение, которое умеет искать и
запускать тесты.

Мы будем пользоваться таким для `unittest`, который уже встроен в Python.

Остальные действуют по тем же принципам с немного другим синтаксисом. Так что если увидите другие тестовые фреймворки,
не пугайтесь, они работают практически так же.

Во встроенном в Python модуле `unittest` есть класс `TestCase`, все тесты должны быть описаны в его наследниках и
название каждого метода должно начинаться с `test`.

### Встроенные `assert`

Вместо обычного `assert` unittest использует свои заготовленные методы. Вот некоторые из них:

```python
import unittest

class T(unittest.TestCase):
    def test_example(self):
        self.assertEqual(2+2, 4)
        self.assertTrue([1])
        self.assertIsNone(None)
        self.assertIn(2, [1,2,3])
        self.assertIsInstance("x", str)
# Дополнительно:
# with self.assertRaises(ValueError): int("x")
# for x,y in [(2,4),(3,9)]:
#     with self.subTest(x=x):
#         self.assertEqual(x*x, y)
```

### Простейший пример

В корне нашего проекта создадим файл `tests.py`

```python
# tests.py
import unittest


class TestSum(unittest.TestCase):
    def test_sum(self):
        self.assertEqual(sum([1, 2, 3]), 6, "Should be 6")

    def test_sum_tuple(self):
        self.assertEqual(sum((1, 2, 2)), 6, "Should be 6")


if __name__ == '__main__':
    unittest.main()
```

Обратите внимание, код заканчивается такими строками:

```python
if __name__ == '__main__':
    unittest.main()
```

Тут это добавлено для того, чтобы мы смогли напрямую явно запустить этот файл как файл с тестами. В реальности так не
делается — дальше покажу, как делается.

Теперь, если мы запустим файл, в котором это написано, мы увидим следующее:

```
$ python tests.py
.F
======================================================================
FAIL: test_sum_tuple (__main__.TestSum)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "tests.py", line 9, in test_sum_tuple
    self.assertEqual(sum((1, 2, 2)), 6, "Should be 6")
AssertionError: Should be 6
----------------------------------------------------------------------
Ran 2 tests in 0.001s
FAILED (failures=1)
```

Один тест успешен, и один упал.

### Запуск и поиск тестов

Для запуска тестов можно использовать встроенную команду, и при её использовании нам не нужно добавлять `main` и запуск
тестов вручную:

```
python -m unittest
```

Если запустить её вообще без параметров, то она будет искать **все** файлы и папки, которые начинаются со слова `test`, и
попытается их запустить.

> При discovery можно указать стартовую директорию (-s). В этом режиме `__init__.py` не обязателен; достаточно, чтобы стартовая директория была на `sys.path`.

Или указать конкретный файл:

```
python -m unittest tests.py
```

Если файл находится в папке, то вот так:

```
python -m unittest folder/tests.py
```

Или использовать режим discovery с указанием стартовой директории и шаблона:

```
python -m unittest discover -s tests -p "test_*.py"
```


Также можно запустить конкретный тест-кейс или даже отдельный тест:

```
python -m unittest tests.TestSum
python -m unittest tests.TestSum.test_sum
```

> Запустить можно как всё целиком, так и любыми необходимыми частями.

### Методы setUp и tearDown

Если добавить методы `setUp` и `tearDown`, то код из них будет исполняться перед каждым тестом и после каждого теста
соответственно.

> Тесты в Python переехали из Java. И это причина, почему названия этих методов не соответствуют PEP8. Просто смирились,
> запомнили и пользуемся.

```python
import unittest


class TestSum(unittest.TestCase):

    def setUp(self):
        self.my_num = 5

    def test_odd(self):
        self.assertTrue(self.my_num % 2, "Number is odd")

    def tearDown(self):
        self.my_num += 1
```

Также есть `setUpClass`/`tearDownClass` (выполняются один раз на класс) и `setUpModule`/`tearDownModule` (один раз на модуль):

```python
import unittest

class TestDatabase(unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        """Выполняется один раз перед всеми тестами класса.
        Используется для дорогих операций: подключение к БД, загрузка данных.
        """
        cls.connection = create_database_connection()
        cls.test_data = load_test_fixtures()

    @classmethod
    def tearDownClass(cls):
        """Выполняется один раз после всех тестов класса."""
        cls.connection.close()

    def setUp(self):
        """Выполняется перед КАЖДЫМ тестом."""
        self.connection.begin_transaction()

    def tearDown(self):
        """Выполняется после КАЖДОГО теста."""
        self.connection.rollback()

    def test_insert(self):
        # Использует self.connection и self.test_data
        pass
```

### subTest — параметризация в unittest

Когда нужно проверить функцию с разными входными данными, используйте `subTest`:

```python
import unittest

class TestMath(unittest.TestCase):

    def test_square(self):
        test_cases = [
            (2, 4),
            (3, 9),
            (0, 0),
            (-2, 4),
        ]
        for x, expected in test_cases:
            with self.subTest(x=x):
                self.assertEqual(x ** 2, expected)
```

Преимущества `subTest`:
- Если один subTest падает, остальные продолжают выполняться.
- В отчёте видно, какой именно случай упал.
- Не нужно писать отдельный тест для каждого случая.

### Пропуск тестов

В пакете `unittest` есть декораторы `skip`, `skipIf` и `skipUnless`.

Необходимы для пропуска ненужных на данном этапе тестов.

Такое бывает нужно, когда ваш код должен поддерживать различные операционные системы или пакеты разных версий. Просто
имейте в виду, что есть такая возможность.

```python
import sys
import unittest

class MyTestCase(unittest.TestCase):

    @unittest.skip("demonstrating skipping")
    def test_nothing(self):
        self.fail("Shouldn't happen")

    @unittest.skipIf(sys.version_info < (3, 11), "Requires Python 3.11+")
    def test_format(self):
        # Tests that work only for certain Python versions
        pass

    @unittest.skipUnless(sys.platform.startswith("win"), "Requires Windows")
    def test_windows_support(self):
        # Windows-specific testing code
        pass
```

## pytest — альтернатива unittest

Хотя мы пока используем `unittest`, на реальных проектах чаще встречается `pytest`. Вот краткое сравнение:

### Базовый пример pytest

```python
# test_example.py
def test_sum():
    assert sum([1, 2, 3]) == 6

def test_sum_tuple():
    assert sum((1, 2, 2)) == 5
```

Запуск: `pytest test_example.py` или просто `pytest` (найдёт все `test_*.py`).

### Сравнение синтаксиса

| unittest                 | pytest             |
|--------------------------|--------------------|
| `self.assertEqual(a, b)` | `assert a == b`    |
| `self.assertTrue(x)`     | `assert x`         |
| `self.assertIn(a, b)`    | `assert a in b`    |
| `self.assertRaises(E)`   | `pytest.raises(E)` |
| Классы обязательны       | Функции достаточно |

### Фикстуры в pytest

```python
import pytest

@pytest.fixture
def sample_list():
    return [1, 2, 3, 4, 5]

def test_sum(sample_list):
    assert sum(sample_list) == 15

def test_len(sample_list):
    assert len(sample_list) == 5
```

### Параметризация тестов

```python
import pytest

@pytest.mark.parametrize("input,expected", [
    ([1, 2, 3], 6),
    ([0, 0], 0),
    ([-1, 1], 0),
])
def test_sum_parametrized(input, expected):
    assert sum(input) == expected
```

> pytest — мощный инструмент с богатой экосистемой плагинов. После изучения pip (лекция 18) рекомендую попробовать его в своих проектах.

## Измерение покрытия кода (Coverage)

Покрытие кода (code coverage) показывает, какой процент кода выполняется при запуске тестов.

### Установка и использование

```bash
pip install coverage

# Запуск тестов с измерением покрытия
coverage run -m unittest discover

# Просмотр отчёта в консоли
coverage report

# Генерация HTML-отчёта
coverage html
# Откройте htmlcov/index.html в браузере
```

### Пример вывода

```
Name                 Stmts   Miss  Cover
----------------------------------------
my_module.py            20      4    80%
utils.py                15      0   100%
----------------------------------------
TOTAL                   35      4    89%
```

### Важные замечания

- 100% покрытие ≠ отсутствие багов. Покрытие показывает, что код выполнялся, но не что он правильный.
- Стремитесь к 80-90% покрытия для критичного кода.
- Не гонитесь за процентами — качество тестов важнее количества.

> Для pytest используйте плагин `pytest-cov`: `pytest --cov=my_module tests/`

## Mock

Мок — это фиктивный объект. Очень часто мы попадаем в такие ситуации, когда в тесте мы не можем выполнить какое-либо
действие. Например, в вашем модуле будет метод, который в реальности возвращает случайное значение.

Но в тесте мы не можем полагаться на случайности, нам нужно протестировать, как именно ведёт себя код в разных случаях.

`Mock` является частью стандартной библиотеки начиная с Python 3.3. Очень вряд ли вы столкнётесь с такими старыми
версиями в современном мире.

### Как это работает?

Можно создать `Mock`-объект и заменить им всё что угодно. Мы можем назначить ему возвращаемый результат для вызова чего
угодно. Таким образом, это объект, который не вызывает ошибку при любом его использовании, и можно в нём настроить любые
атрибуты или методы.

```python
from unittest.mock import Mock

mock = Mock()
mock.some_attribute  # всё ок, несуществующий атрибут существует
mock.any_method()  # опять всё ок, и всё существует
mock.method1().attr1.attr2.method2()  # так тоже всё ок, любой атрибут или метод будет возвращать Mock-объект
```

Мы можем использовать фейковый объект в качестве аргумента или целиком заменить им сущность:

```python
# Pass mock as an argument to do_something()
do_something(mock)

# Patch the random library
random = mock
```

Есть достаточно много способов использовать `Mock`. Очень хорошая
статья [тут](https://realpython.com/python-mock-library/).

Рассмотрим основные.

### Контроль возвращаемого результата

Предположим, вам нужно убедиться, что ваш код в будни и в выходные дни ведёт себя по-разному, а код подразумевает
использование встроенной библиотеки `datetime`.

Для упрощения пока засунем всё в один файл:

```python
from datetime import datetime


def is_weekday():
    today = datetime.today()
    # Python's datetime library treats Monday as 0 and Sunday as 6
    return 0 <= today.weekday() < 5


# Test if today is a weekday
assert is_weekday()
```

Если мы запустим этот тест в воскресенье, то получим `exception`. Что же с этим делать? Замокать! `Mock`-объект
может возвращать по вызову любой функции необходимое нам значение посредством заполнения `return_value`.

```python
import datetime
from unittest.mock import Mock

# Save a couple of test days
tuesday = datetime.datetime(year=2019, month=1, day=1)
saturday = datetime.datetime(year=2019, month=1, day=5)

# Mock datetime to control today's date
datetime = Mock()


def is_weekday():
    today = datetime.datetime.today()
    # Python's datetime library treats Monday as 0 and Sunday as 6
    return 0 <= today.weekday() < 5


# Mock .today() to return Tuesday
datetime.datetime.today.return_value = tuesday
# Test Tuesday is a weekday
assert is_weekday()
# Mock .today() to return Saturday
datetime.datetime.today.return_value = saturday
# Test Saturday is not a weekday
assert not is_weekday()
```

> В этом примере, мы заставили библиотеку `datetime` не возвращать реальные результаты, а возвращать то, что нужно нам.

> Детально изучите этот пример!

Если нам необходимо, чтобы после повторного вызова мы получали другие результаты, то нам поможет `side_effect`. Работает
так же, как и `return_value`, только принимает перебираемый объект и с каждым вызовом возвращает следующее значение.

```python
mock_poll = Mock(side_effect=[None, 'data'])
mock_poll()
# None
mock_poll()
# 'data'
```

Или как в прошлом примере:

```python
import datetime
from unittest.mock import Mock

# Save a couple of test days
tuesday = datetime.datetime(year=2019, month=1, day=1)
saturday = datetime.datetime(year=2019, month=1, day=5)

# Mock datetime to control today's date
datetime = Mock()


def is_weekday():
    today = datetime.datetime.today()
    # Python's datetime library treats Monday as 0 and Sunday as 6
    return 0 <= today.weekday() < 5


# Mock .today() to return Tuesday first time and Saturday second time
datetime.datetime.today.side_effect = [tuesday, saturday]
assert is_weekday()
assert not is_weekday()
```

### Декоратор patch

Допустим, у нас есть класс, где мы вызываем модуль `random` (как будет в вашем модуле), но для тестов нам не подходит
случайность:

```python
import random


class Randomizer:
    def value_from_list(self, some_list: list[int]) -> str:
        return f"{random.choice(some_list)}!"
```

> Этот код будет возвращать случайное значение из списка.

И тест к этой функции:

```python
from unittest import TestCase
from main import Randomizer


class TestCalculator(TestCase):
    def setUp(self):
        self.rand = Randomizer()

    def test_sum(self):
        answer = self.rand.value_from_list([1, 2, 3, 4])
        self.assertEqual(answer, "?!")  # С чем будем сравнивать? мы не знаем какое значение нам вернется
```

На самом деле тестировать функцию, которую мы импортировали из стандартной библиотеки, не нужно. Но если есть хоть
какие-то наши изменения, то уже очень нужно.

Как протестировать наш метод? Замокать случайность.

```python
from unittest import TestCase
from unittest.mock import patch
from main import Randomizer


class TestCalculator(TestCase):
    def setUp(self):
        self.rand = Randomizer()
        self.values = [1, 2, 3, 4]

    @patch('main.random.choice')
    def test_value_from_list(self, choice_mock):
        choice_mock.return_value = 1
        result = self.rand.value_from_list(self.values)
        self.assertEqual(result, "1!")
        choice_mock.assert_called_once_with(self.values)

```

Пропатченные методы попадают в аргументы метода теста:


### Полезные приёмы с mock

```python
from unittest.mock import patch
# Контекст-менеджер и autospec (проверка сигнатур)
with patch('main.random.choice', autospec=True) as ch:
    ch.return_value = 2
    # вызов кода, который внутри использует random.choice(...)
```

### Рекомендации по тестам (best practices)

- AAA: Arrange → Act → Assert (структурируйте тесты).
- Детерминированность: избегайте случайностей/зависимости от времени; используйте mock.
- Изоляция внешних ресурсов: файлы через tempfile, сеть/БД — мокать.
- Небольшие, быстрые, независимые юнит-тесты; интеграционные — реже.
- Coverage: измеряйте покрытие (концептуально); качество важнее «процентов».

## Практика

В качестве практики я вам покажу, как в целом пишутся тесты на примере написанного модуля.

В идеале вы сами должны покрыть свой модуль тестами целиком!

---

[← Лекция 12: Декораторы. Декораторы с параметрами. Декораторы классов (staticmethod, classmethod, property)](lesson12.md) | [Лекция 14: Проектирование. Паттерны. SOLID. →](lesson14.md)
